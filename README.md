# dsa-real-time-etl-airflow-spark-kafka
Projeto Kafka + Spark + Cassandra + Airflow

# Pipeline de Processamento de Dados em Tempo Real com Kafka, Spark, Cassandra e Airflow

Este projeto implementa uma arquitetura moderna de dados em tempo real, baseada no padrÃ£o **Cliente-Servidor**, utilizando:

- Apache Kafka
- Apache Spark Structured Streaming
- Apache Cassandra
- Apache Airflow
- Docker + Docker Compose

---

## Objetivo do projeto

Criar um pipeline de ingestÃ£o e processamento de eventos de dados em tempo real, com:

âœ… GovernanÃ§a e rastreabilidade dos dados  
âœ… AutomaÃ§Ã£o e orquestraÃ§Ã£o de pipelines  
âœ… SeparaÃ§Ã£o clara de responsabilidades entre infraestrutura (servidor) e lÃ³gica de negÃ³cio (cliente)  
âœ… Escalabilidade e resiliÃªncia  
âœ… Capacidade de resposta em tempo real para o negÃ³cio  

---

## ğŸ—ºï¸ Arquitetura geral do projeto

### ğŸ—ï¸ Modelo Cliente-Servidor

Neste projeto, a arquitetura segue um modelo **Cliente-Servidor bem definido**:

### ğŸ”¹ Servidor (Infraestrutura - containers orquestrados)

- **Kafka Broker** â†’ gerenciamento de mensagens em tempo real
- **Schema Registry** â†’ controle de formatos de mensagens Kafka
- **Kafka Control Center** â†’ observabilidade da stack Kafka
- **Apache Spark Master e Worker** â†’ cluster de processamento de dados
- **Apache Cassandra** â†’ banco NoSQL para persistÃªncia dos dados
- **Apache Airflow** â†’ orquestraÃ§Ã£o e automaÃ§Ã£o de workflows
- **Postgres** â†’ backend de metadados para o Airflow

Todos estes componentes sÃ£o orquestrados pelo `docker-compose.yml`, e formam a **plataforma de dados e processamento** do projeto.

---

### ğŸ”¸ Cliente (LÃ³gica de processamento - container separado)

- **dsa_cliente** â†’ container separado que executa um consumidor Kafka implementado com Spark Structured Streaming.
- ResponsÃ¡vel por:
  - Consumir eventos do Kafka topic `dsa_kafka_topic`.
  - Processar e transformar os dados com Spark.
  - Persistir os resultados no Cassandra.
- Totalmente isolado da infraestrutura â†’ permite escalar horizontalmente e atualizar a lÃ³gica de negÃ³cio sem impactar os serviÃ§os core.

---

## ğŸ” Fluxo da arquitetura

```text
Kafka Producer (mockado) â†’ Kafka Broker â†’ Cliente Kafka-Spark-Cassandra (dsa_cliente) â†’ Cassandra DB â†’ Airflow (orquestraÃ§Ã£o futura)
Rede
Todos os containers estÃ£o conectados na rede dsaservidor_dsacademy, garantindo comunicaÃ§Ã£o segura e isolada.

âš™ï¸ Tecnologias utilizadas
Apache Kafka

Apache Spark

Apache Cassandra

Apache Airflow

Docker

Docker Compose

ğŸ—‚ï¸ Estrutura do projeto
text
Copiar
Editar
/
â”œâ”€â”€ dags/                             # DAGs do Airflow
â”œâ”€â”€ entrypoint/                       # Entrypoint do Airflow
â”œâ”€â”€ modulos/                          # MÃ³dulos auxiliares (montado como volume)
â”œâ”€â”€ requirements.txt                  # DependÃªncias Python
â”œâ”€â”€ Dockerfile                        # Imagem do dsa_cliente (Kafka-Spark-Cassandra Consumer)
â”œâ”€â”€ docker-compose.yml                # OrquestraÃ§Ã£o de todos os containers
â”œâ”€â”€ dsa_consumer_stream.py            # Kafka-Spark-Cassandra Consumer (CLIENTE)
â””â”€â”€ README.md                         # DocumentaÃ§Ã£o do projeto
ğŸš€ ExecuÃ§Ã£o do projeto
1ï¸âƒ£ Subir os containers de infraestrutura (Servidor)
bash
Copiar
Editar
docker-compose pull
docker-compose up -d
2ï¸âƒ£ Criar a imagem do dsa_cliente
bash
Copiar
Editar
docker build -t kafka-spark-cassandra-consumer .
3ï¸âƒ£ Rodar o container dsa_cliente (Cliente separado)
bash
Copiar
Editar
# Exemplo modo inicial (reprocessar histÃ³rico):
docker run --name dsa_cliente --network dsaservidor_dsacademy kafka-spark-cassandra-consumer python dsa_consumer_stream.py --mode initial

# Exemplo modo append (tempo real):
docker run --name dsa_cliente --network dsaservidor_dsacademy kafka-spark-cassandra-consumer python dsa_consumer_stream.py --mode append
ğŸ“ Detalhamento do Kafka Consumer (Cliente)
O consumer dsa_consumer_stream.py:

âœ… Se conecta ao tÃ³pico dsa_kafka_topic no Kafka
âœ… Usa Spark Structured Streaming para consumir e transformar os dados
âœ… Converte os dados em DataFrame estruturado
âœ… Realiza sanitizaÃ§Ã£o e filtragem dos dados
âœ… Insere os dados na tabela dsa_dados_usuarios.tb_usuarios no Cassandra

Schema da tabela Cassandra:
sql
Copiar
Editar
CREATE TABLE IF NOT EXISTS dsa_dados_usuarios.tb_usuarios (
    id TEXT PRIMARY KEY,
    first_name TEXT,
    last_name TEXT,
    gender TEXT,
    address TEXT,
    post_code TEXT,
    email TEXT,
    username TEXT,
    dob TEXT,
    registered_date TEXT,
    phone TEXT,
    picture TEXT
);
âœ… Problemas enfrentados e soluÃ§Ãµes aplicadas
SeparaÃ§Ã£o Cliente-Servidor
â†’ A arquitetura Cliente-Servidor foi adotada para garantir:

âœ… Isolamento da lÃ³gica de negÃ³cio â†’ o dsa_cliente Ã© container separado.
âœ… Escalabilidade â†’ Ã© possÃ­vel rodar mÃºltiplos consumidores Kafka em paralelo.
âœ… IndependÃªncia â†’ alteraÃ§Ãµes no cÃ³digo do cliente nÃ£o afetam os serviÃ§os core.

RestriÃ§Ãµes de permissÃµes no ambiente local
â†’ Uso de containers para isolar dependÃªncias e evitar problemas com permissÃµes no Windows.

ComunicaÃ§Ã£o entre containers
â†’ Rede dsaservidor_dsacademy criada no Compose â†’ cliente explicitamente conectado Ã  mesma rede.

Problema com entrypoint do Airflow Webserver
â†’ chmod removido do entrypoint â†’ script executado diretamente.

Kafka Consumer otimizado
â†’ Uso de Spark Structured Streaming para garantir escalabilidade e performance.

ğŸš€ BenefÃ­cios da arquitetura
âœ… Arquitetura Cliente-Servidor escalÃ¡vel e modular
âœ… Processamento de dados em tempo real
âœ… SeparaÃ§Ã£o de responsabilidades entre infraestrutura e lÃ³gica de consumo
âœ… Flexibilidade para evoluir novos casos de uso
âœ… Modularidade e escalabilidade (consumidores Kafka isolados em containers separados)
âœ… GovernanÃ§a e rastreabilidade dos pipelines de dados
âœ… Infraestrutura como cÃ³digo com Docker Compose

ğŸŒ AplicaÃ§Ãµes reais
Monitoramento de operaÃ§Ãµes em tempo real

AnÃ¡lise de comportamento de usuÃ¡rios

DetecÃ§Ã£o de anomalias em processos industriais

Suporte a dashboards de inteligÃªncia operacional

Enriquecimento de dados em tempo real

ğŸ“š Aprendizados
âœ… SeparaÃ§Ã£o de responsabilidades entre servidor e cliente Ã© essencial para arquitetura escalÃ¡vel.
âœ… Kafka + Spark + Cassandra Ã© uma stack extremamente poderosa para pipelines em tempo real.
âœ… AutomatizaÃ§Ã£o e containerizaÃ§Ã£o reduzem drasticamente a complexidade operacional.
âœ… Monitoramento, logging e governanÃ§a sÃ£o peÃ§as fundamentais de uma arquitetura de dados moderna.

ğŸ“Œ PrÃ³ximos passos
Implementar batch inserts para Cassandra

Automatizar execuÃ§Ã£o do dsa_cliente com DAG do Airflow

Implementar monitoramento de offsets do Kafka

Instrumentar mÃ©tricas no Control Center

Validar escalabilidade com mÃºltiplos consumers concorrentes

ğŸ¤ ContribuiÃ§Ã£o
Este projeto foi implementado como parte de estudos e prÃ¡tica de arquitetura de dados em tempo real e automaÃ§Ã£o de pipelines crÃ­ticos, com o objetivo de explorar boas prÃ¡ticas e padrÃµes de mercado.

ContribuiÃ§Ãµes e sugestÃµes sÃ£o sempre bem-vindas!
